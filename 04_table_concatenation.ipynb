{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# For the local thickness concatenation"
      ],
      "metadata": {
        "id": "bERKbui-w7b-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "wFhTgR-TxZI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "zip_file_path = '/content/Analysis.zip' # if a zip file is used (Optional)\n",
        "folder_path = '/content/Analysis' # path with the local thickness .csv files\n",
        "output_localthickness = '/content/20240508_Dataset_localthickness.xlsx' # Output path and name ending with .xlsx of the excel file with concatenated csvs"
      ],
      "metadata": {
        "id": "zJIVQXxVvFU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional)\n",
        "import zipfile\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "metadata": {
        "id": "rSEAwFfVoPi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BX5upkPKgFdA"
      },
      "outputs": [],
      "source": [
        "# prompt: Extract csvs from zipped folder Analysis.zip containing Analysis folder which contains many csvs\n",
        "# !unzip Analysis.zip\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the directory containing your CSV files\n",
        "folder_path = '/content/Analysis'\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Initialize an empty list to hold dataframes\n",
        "dataframes = []\n",
        "\n",
        "# Iterate through each CSV file\n",
        "for csv_file in csv_files:\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(os.path.join(folder_path, csv_file))\n",
        "    # Add a new column with the name of the CSV file (without .csv extension)\n",
        "    df['source_file'] = os.path.splitext(csv_file)[0]\n",
        "    # Remove 'denoising_000_' from the source_file names\n",
        "    df['source_file'] = df['source_file'].str.replace('denoising_000_', '', regex=False)\n",
        "    # Append the dataframe to the list\n",
        "    dataframes.append(df)\n",
        "\n",
        "# Concatenate all dataframes into a single dataframe\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Export to an excel file\n",
        "combined_df.to_excel(output_localthickness)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For the pooled results"
      ],
      "metadata": {
        "id": "24VtToKww04l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "T6uljxz0xkVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "file_path = '/content/Pooled_Results.csv' # Path of the pooled results csv file\n",
        "output_pooled = '/content/20240508_Dataset_Pooled_Results.xlsx' # Output path and name ending with .xlsx of the excel file"
      ],
      "metadata": {
        "id": "AQ9XG5KFxwh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove 'denoising_000_' from the source_file names\n",
        "df['Filename'] = df['Filename'].str.replace('denoising_000_', '', regex=False)\n",
        "\n",
        "# Group by 'Filename' and calculate the total cyst volume\n",
        "grouped_df = pd.DataFrame()\n",
        "grouped_df['Organoid volume (um^3)'] = df.groupby('Filename')['Organoid volume (um^3)'].mean()\n",
        "grouped_df['Cyst volume (um^3)'] = df.groupby('Filename')['Cyst volume (um^3)'].sum()\n",
        "grouped_df['Cyst fraction'] = grouped_df['Cyst volume (um^3)']/grouped_df['Organoid volume (um^3)']\n",
        "\n",
        "# Export to excel file\n",
        "grouped_df.to_excel(output_pooled)"
      ],
      "metadata": {
        "id": "WdSzWlk1w0SF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}